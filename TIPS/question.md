
1.兴趣是最好的老师

大学都喜欢用C语言或者C++来作为编程教学的第一门语言，当时大一一整年学习的都是C系列的这两门语言，当时对自己的未来出路基本上没有任何想法， 做的基本上都是那种杨辉三角，水仙花数这样的小程序，对市面上形形色色的复杂的应用怎么写出来的一点概念没有。但是很好奇。
但是大一的课程比较忙，直到大二才开始自学的Java这门语言，当时从C++切换到Java最直观的感觉就是没有指针了，大一用C++感觉10个异常有8个是指针指错地方，Java没有指针的特性当时确实让我感觉比较舒适，喜欢，好用。一开始也是认为现在用的东西都是Java那个图形化界面做的呢，后来学习到Springboot框架才发现真个Java的知识体系很庞大，决定好好学习这门技术，想要以Java后端开发作为自己的职业。

2.保研失利

前面提到我学分绩在前20%，其实在上上个学期结束之后，我的学分绩大概是在百分之16%，当时距离保研线基本上是差四五，五六名大概。当时那个学期也是努力学了一把，当时那一个单一学期的学分绩能达到前10%，但是只前进了2名，所以上学期开始果断选择了放弃争保研这条路，投入到春招的暑期实习当中去。

3.塞翁失马，焉知非福

为什么这么说呢，因为来用友工作之后我发现，我这个人的性格更加适合工作，在可预见的时间内能够看到自己的劳动成果，而且是比较实际的劳动成果，这种成就感让我很有动力，读研的话感觉要有做大量工作，但是看不到实际成果的准备。相比之下，我更喜欢前者，工作使我快乐。刚来的头一个多月基本都是10点之后走的，经常最后一个走的时候自己关灯，虽然有因为刚来业务逻辑不熟悉导致工作慢的原因，但更因为我充满工作激情。

### 自我介绍

我叫***，来自哈尔滨工业大学软件工程专业。非常高兴能够参加这次面试。

我最早是在大二的时候接触的java，java没有指针的特性吸引了我，大一一直使用c系列的语言学习的很是痛苦，后来为了加入学校的工作室学习了spring框架相关的知识，并独立开发了一些项目。才感受到java知识体系的庞大，起初我认为java的图形界面和io流读取文件就是现在的程序，直到我一步步深入才发现java远不止这些，于是我决定好好学习java这门技术。

在校期间开发过一个api开放平台，主要工作有实现web系统的业务逻辑、通过网关实现路由转发等功能，实现了集中进行签名校验，接口调用统计等业务逻辑，使用dubbo框架实现网关模块对web系统模块的接口调用。

其次还开发过一个匹配交友平台，主要工作有实现主要的业务逻辑，通过redis缓存首页用户列表，通过spring scheduler 实现缓存预热，解决了同一用户重复入队问题，实现了匹配相似用户的功能。

### 项目经历

**api开放平台：**

这个项目业务具体的业务逻辑并不是很难，主要是在系统架构设计方面和细节方面和普通增删改查项目不大一样，
业务逻辑上，无非就是要开放接口的增删改查和发布下线这些东西。
在系统架构上，首先要开放的接口本身和管理接口的后台肯定是要分开两个模块，
用户如果想要在自己的代码里调用我们的接口，肯定要符合我们接口的一些规范，比如要携带ak和sk等请求头啦，参数要符合条件等。
为了减少用户在这上面的代码开发，就要设计一个客户端sdk模块，这个模块可以向我们的接口地址发送请求，并按照平台要求携带相应信息。
发送了请求之后，我们的接口需要验证用户身份，记录接口被用户调用的次数等业务逻辑，每个接口如果都加上这段逻辑的话比较麻烦，也污染接口。
如果使用aop的话，假设有别的开发者在我们的平台上线接口，他们都要把我们这段aop逻辑加进去也比较麻烦，所以最后选用了网关。
客户端sdk不直接发送请求到被调用的接口，而是发送到网关，由网关来统一进行业务逻辑并转发，还可以实现流量染色和访问控制等高级功能。
网关模块需要调用接口管理后台的一些功能，比如统计调用次数，查看用户和接口是否存在等业务逻辑，可以使用直接导包或者调用http请求或者rpc方式，但是rpc方式更加快速，就像调用自己的方法一样，最后选用了dubbo框架进行远程调用。
通过这段项目经历，对网关和rpc的使用场景有了基本的了解。

**匹配交友平台：**

这个项目主要是一些业务逻辑中的细节需要多加考虑。
首先为了防止用户在获取首页上用户列表时需要等待较长的时间，使用了redis来存储相应的内容，为了防止用户信息改变导致数据库和缓存数据差距过大，给redis设置了过期时间。但是这样设计的话容易让每天的第一个用户访问数据比较慢。又添加了定时任务，每天固定时间会将数据存储到redis中，并且使用了redisson分布式锁来保证多机部署时不会重复执行的问题。
第二个点是在加入队伍时，为了防止人数超出限制和多次加入同一个队伍这个问题，并且不会过多的影响性能，使用了redisson分布式锁和synchronized和redis事务来实现。
不少地方使用了redis缓存来读取数据

通过这段项目经历，学习了对redis的事务和锁相关知识。

**项目中遇到的困难：**

一开始匹配在制作匹配相似用户的时候，因为我这个相似度是根据标签相同的个数来判断的，相同标签数量越多相似度就越高，一开始项目没用redis的时候这一块确实实现的非常麻烦，因为当时我数据库用户数量存了一万多个，因为大数据方面的知识确实不是很了解，只能就是把数据从数据库里面取出来，然后挨个和登录用户的标签进行比较，把前几名筛选出来然后返回，然后写完之后一测接口好像响应时间都超过一秒了。当时感觉肯定是数据库中取出大量数据太慢了，一开始我先把从数据库中取出数据的所有字段的改成了只取出id和标签两个字段，比较完取出前几名的之后再通过id字段把对应用户的全部数据取出来，但是很麻烦，因为先搞好存储了前几名的id的list后，用户数据库的in那个条件查询数据库又会把顺序打乱，还要在排序，虽然因为筛选的数量比较少不会浪费很多性能，但是代码写起来有点麻烦，后来加上了redis，就方便了许多，因为即使一次性把所有字段从redis中取出来也不会耗费很长时间。所以redis确实是个好东西。

网关异步
我选用了springgateway来作为网关，并在网关模块是实现了一些业务逻辑，比如参数和用户权限的校验，这些逻辑是放到调用实际接口之前的，还有统计接口统计次数的逻辑和响应日志这些是放在接口响应之后的，一开始我在网关的那个filter函数里面先写了请求之前的逻辑，然后根据响应的状态码，比如如果状态码为ok那就执行成功调用接口的逻辑，然后调试时发现还没等到接口被调用，响应后的逻辑就被执行力，通过搜索发现filter.chain是个异步操作，方法return后才调用了模拟接口，然后使用了网上提供的response装饰者对response进行了增强，才把业务逻辑加进去。

加入队伍锁
我这个队伍设置的是一个人最多能加入5个队伍，然后队伍也有人数限制，为了防止自己多次加入同一个队伍和多个队伍同时加入一个队伍导致队伍人数超出限制，就需要加锁，一开始直接加的synchronized锁，但是这样锁的粒度太大了，因为其实上面两种情况下加的锁应该是包含关系，一个是锁住当前用户和当前用户加入的队伍，一个是锁住一个队伍，所以后来就在外围加了一个redisson分布式锁，只锁住用户id和队伍id都相同的线程，内层加了一个队伍id相同的redisson分布式锁。

### 产品介绍

我们部门是叫主数据产品开发部，做的系统的主要功能就是管理主数据，他是我们用友BIP这么一个大的企业创新平台的一个模块的一个功能。主数据就是企业业务的主干数据，基础稳定的数据。比如说人力资源，客户，供应商，物料，行政区划啥的。我感觉我们做的这个系统有点像一个能连接生产系统和消费系统获取和消费数据的一个MySQL，功能和MySQL这种数据库很像我感觉。

最简单的使用流程就是可以通过别的系统导入或者自己创建模型，一个模型可以有一个主实体多个子实体，实体有自己的属性，有点像数据库的表的那种形式。然后就是需要配置编码规则啥的，就是每一条数据都有自己的流水号，往模型导入数据之前需要配置好这个编码规则，然后导入的数据就都会自动生成自己的流水号。然后再根据需要配置生产系统或者是消费系统。然后对刚才配置的集成系统进行授权，可读可写可分发之类的。然后如果是生产系统的话就可以进行数据导入，如果是消费系统就可以往里分发数据进行使用。

这差不多讲就是最简单的那一套使用流程，就是最基本的功能。然后还有一些就是再这套最简单的流程上面的一些升级功能，比如流程模型，就是可能建立一个流程然后可以按照流程进行审核，数据清洗，就是按照自己配置的规则找出脏数据之类的。然后还有日志管理、统计分析等一些功能。还是挺复杂的这个系统。

### 实习经历

使用压测工具配合Arthas来监测主数据系统中通过接口导入数据和查询数据的功能。进行代码优化，包括代码逻辑优化，序列化器优化，缓存优化，数据库优化，线程池和JVM优化等。在200的并发量下，QPS从20提升到200。正常情况下200用户并发压测接口耗时：0.9s，100用户并发接口平均耗时：0.4s
重构通过excel导出数据的代码逻辑。去除全局变量，将一次导出改为流式分批导出，防止并发错误，减少内存消耗。
重构通过excel导入数据的代码逻辑。从转化为csv格式导入改为使用Easyexcel直接导入，优化代码逻辑，导入200M左右excel时间从150s左右提升至70s左右。流式分批导入情况下减少数据获取次数，在不显著增加内存消耗的前提下，大幅减少了响应时间。
解决客户的支持问题，与客户交流实时解决问题。
解决业务Bug，提高debug和阅读源码能力。

1. 熟悉业务
刚进来的时候，一开始花了两周时间吧，熟悉代码，一开始说实话很懵逼，当时部门经理把我们部门项目的GitLab权限给我，说让我熟悉熟悉代码，我拉下来，用idea上一个插件，能看代码行数的，好像是叫statistic，我一看总计是五十多万行，Java代码大概是三十多万，我靠，看傻了都给我，没见过这么多代码。当时部门经理也是给我讲了讲我们这个系统的业务逻辑啥的，都有啥功能，系统是做什么的那些，界面上每个模块都是干啥的给我讲了讲，也是给我说了说哪些功能模块是比较重要的。前两天就找了几个接口，debug调试了一下，后来部门经理给我说使用接口导入主数据这个功能，基本上包含了大部分基础的逻辑，你可以跟着这个流程走一遍。后面我就debug，熟悉业务。花了两个星期。

2. 压测
一开始的时候也是分配一些bug给我改，然后就是这个压测，压测通过调用接口导入数据和查询数据这两个接口，压测用的是我们自己的压测工具，叫啥iuap Runner，挺老的一个压测工具，但是应该是比较适合我们业务，然后配合Arthas去监测每个方法的耗时，但是老大说的是高于5ms的方法都要看，一个方法一个方法的扣。一开始整个执行一次导入的时间还是挺久的，如果这个模型创建的比较复杂，比如说有很多参照和子表啥的，可能执行一次要十几秒。
	1. 一开始是在参照字段添加了索引？？？（咋加的？），加个索引直接就从10s提升到2s了差不多。
	2. 然后发现这个Redis耗时比较严重，因为Redis调用的次数很多，如果操作的是大对象的话，一开始一次大概就得10ms，追进去发现他这个序列化和反序列化很慢，就调查了几个主流的序列化器，挨个试了试，最后选的Kryo这个序列化器，大概能提升到5ms左右。
	3. 然后就是优化一些代码的逻辑。最后是将200用户并发的情况下，平均事务执行时间从2s降到了1s。

3. 发现问题
然后代码当时看的是基本上没啥可以优化的点了，但是压测的时候发现一个问题，就是每次大概跑到10分钟到15分钟左右的时候，那个事务执行时间就猛的一下子涨上去了。从正常的一秒直接到十几秒。也找不到啥原因。最后把问题报给大佬，让他们分析了一波。发现这个一压测个十几分钟，这个老年代基本上把jvm的内存就占满了，占比大概有个七八十好像是。最后经过大佬的一通分析，终于找到问题了，他是因为，装载数据的时候系统会记录日志，可以从一个界面去查询，什么时候插入了几条数据，成功失败，插入的数据是啥，租户是谁一堆信息。刚才就是说那个插入集成日志的过程还是比较复杂的，当时业务逻辑是写了个异步线程，把这个集成日志来异步写入，不耽误主线程。但是传到异步线程的这个对象比较大，就是插入的那些主数据相关的一些信息。然后并发量又比较大，主要是但是线程池的核心线程数和最大线程数设置的都是10个，主要是这种给公司用的系统平时也没啥并发，就设置的不大，然后这些个异步线程就阻塞在那个等待队列里面，传进去的对象还比较大，时间一长就崩了。首先就是把这个核心线程数和最大线程数都搞到200了，就是压测时用的那个用户数。然后也优化了这个异步线程的代码。一开始这个写日志大概一次要200ms，修改了一些代码逻辑，改完代码大概到150ms差不多。

4. 导入导出
后来也是给我发了几个故事，用友这边需求叫故事，写新功能叫写故事，挺有意思的感觉。故事就是重构一个功能的代码，是用excel导出数据的这个代码，一开始时候的逻辑用了大量的全局变量，把一些通过参数传过来的对象都当service的成员变量存起来了，这样的话并发的时候会出问题，还有就是一开始他的逻辑是把所有的数据都存到内存里面，然后用easyexcel统一写道excel文件里面，但是有的时候某一个实体的数据量可能很大，几百万几千万的话有可能很占用内存，然我改成那个流式导出，可能每几千几万条数据就先写到excle里面，一批一批的写入，大概是这么个故事，还有就是装载，刚才那个不是用excel导出数据吗，又改了一个excel装载数据的接口，一开始他那个逻辑很耗时，比较原生，毕竟老代码了。他是将excel文件转成csv格式的一个字节数组，然后读取数据都是通过解析字节数组来进行的。它使用流式分批导入的，但是这个模型的数据，是有一主多子这么一种情况的，如果一共有1000条数据，他一批是50条，他就先去主表读50条数据，然后就遍历所有子表的所有数据，找到这50个主表数据的子表数据，每50条都进行这个过程，就很费时间，老大也是发现这个问题给我说，让我用直接用easyexcel直接都出来就行，别用csv了，代码很难理解。因为要是想不每一批数据都去查所有的子表，只能就是提前把子表数据都读出来，存到map里面，然后主表根据外键啥的去找。期间也是碰见一些问题吧，这个导入的主要功能也是异步执行的，主线程就一个校验excel的数据跟你导入的实体能不能对的上，是不是符合系统的规则这些，真正的导入都在异步线程里面，一开始把文件MultipartFile直接传入到了异步线程里面，但是解析不了，查了查才知道这个大文件如果超过10M的话就直接在主线程结束时销毁，不会传进去，就改成了用流来导入啥的，改完了以后，用arthas 抓了一下那个异步的方法，发现用easyexcel比老逻辑还慢，最后又追到主线程里面，发现以前的方法是先将excel转化为字节数组的过程是在主线程执行的，然后把字节数组传到异步线程里面，然后读取数据都是从字节数组里面，我那个是读取文件+处理数据都在异步线程，而且主要的耗时点就在那个文件转化的过程里面，肯定他比我快，而且老方法还是在主线程里面进行的这个慢的过程，一个200m的excel大概要转化两分钟，果断换成了我的方法，虽然我那个方法一次把所有的数据都导出来了，但是也不比之前的流式导出使用的内存多，测试完以后也是换了我的方法。


### 遇到的问题

当时也是压测的时候遇见的问题，当时是有一个方法是根据主键获取子表的实体对象和字段属性，返回的是一个List，如果这个实体没有子表的话那么这个返回的应该就是一个空的List，一开始这个方法没加缓存，就是直接查库获取的，然后让我给加了个缓存。加完缓存之后就遇见一个问题，就是压测的时候，有的时候这个方法返回的是一个存有两个null元素的List，就很奇怪。

我先说说我咋写的吧，就是一开始前面先判断缓存里面有没有，如果有的话直接返回，没有的话就查数据库，如果数据库里面查出来是空的，那就往里面lpush一个第一个元素为null的List，然后也加了分布式锁，只有获取到锁了才能往里添加元素，锁的时间设置的10s。按理说应该只有一个能够获取到锁然后往缓存里面写数据。

它既然添加了两个null，就说明这个分布式锁肯定是没锁住，我当时也是不知道为啥没锁住，然后问的组里的人，当时猜测是，压测的时候用的是200用户的并发，可能把数据库连接池占满了，阻塞在这个查库这里了，然后锁都超时了才判断这个分布式锁的setnx。导致往里面查了两个null。

其实挺好改，就是往里面就放一个空的List就没事，没必要非得加一个null。但是这里面事还挺多的。后来也是学了学分布式锁的那些东西。需要注意的东西还挺多的说实话。

### 支持问题


基本上是要和客户远程看一下他们的系统，



这个日志还是比较详细的，我当时还跟一个客户连线，解决他这个系统的问题，当时他说这个集成日志这一块打开需要将近30s，问我怎么优化一下，这个用户的系统是很老的版本了，现在版本集成日志有一个整合，比如说一次插入1000条主数据，在集成日志这个界面都是一条纪录，点击详情，才会展示集体的日志详情，每一条数据的插入情况啥的，还有日志归档啥的功能，这个用户的老版本没有，三四年前的版本了都是，当时那个版本的集成日志就是一条数据就是一条日志，然后我打开一看，两千多万条日志，加载肯定慢的一批，就联系客户给他删了删，留了半年的，又给他写了个定时任务就是定时删除半年前的日志。就好多了。跑题了，